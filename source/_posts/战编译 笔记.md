# lexical analysis
![[Pasted image 20251111194241.png]]
- 输入：代码字符串
- 输出：token-lexeme pairs构成的一个串
## token, nontoken, lexeme
![[Pasted image 20251111194327.png]]token，nontoken——nontoken（空格等）不可在lexical analysis前全部丢掉

## 正则表达式
- If A is a regular expression then we write L(A) to refer to the language denoted by A
![[Pasted image 20251111192554.png]]![[Pasted image 20251111192613.png]]![[Pasted image 20251111192625.png]]![[Pasted image 20251111192700.png]]![[Pasted image 20251111192714.png]]![[Pasted image 20251111192734.png]]
## 使用正则表达式进行lexical analysis的思路
![[Pasted image 20251111192930.png]]![[Pasted image 20251111192950.png]]![[Pasted image 20251111193021.png]]按照写出的正则表达式从左到右进行匹配，从原来的代码字符串中一个一个地提取出lexeme（匹配到whitespace这样的non-token直接丢掉）![[Pasted image 20251111193119.png]]
### 问题1：Ambiguity
#### 匹配长度的问题
![[Pasted image 20251111193254.png]]
对"foo+3"进行parse时，"f"可以是identifier，"fo"也可以说是identifier...
**解决方法**：Maximal match rule——Pick the longest possible substring that matches R
#### 匹配优先级的问题
![[Pasted image 20251111193437.png]]某个substring可能可以同时被匹配为不同token
**解决方法**：手动指定不同token的匹配优先级，优先匹配为顺序在前的
### 问题2：错误处理
![[Pasted image 20251111193652.png]]
为“parse失败”的情况添加一个Error类型的token
## Tiger Language
未整理，见3.pptx，以及书上
## 根据上述思路，利用自动机实现代码
使用flex等工具——编程者提供正则表达式，即可自动生成lexical analysis的代码
### DFA与NFA的对比
#### Deterministic Finite Automata
![[Pasted image 20251111194555.png]]![[Pasted image 20251111194749.png]]![[Pasted image 20251111194809.png]]
#### Non-deterministic Finite Automata
![[Pasted image 20251111194914.png]]状态转换具有不确定性，只要“有可能”到达accept状态即为accept![[Pasted image 20251111195001.png]]
#### NFA与DFA
- 二者的表达能力相同
- NFA比较容易人类构造出，简洁且省空间
- DFA比较容易转换为代码
因此，Lexical Analysis的实现方式为：**把RE转换为NFA，将NFA转换为DFA，然后将DFA转换为代码**
### 将RE转换为NFA
先画出一个一个“小组件”，然后拼装起来
![[Pasted image 20251111201320.png]]![[Pasted image 20251111201329.png]]![[Pasted image 20251111201723.png]]
### 将NFA转换为DFA
![[Pasted image 20251111201833.png]]思路：在根据输入序列而发生状态变化的过程中，DFA的每个状态都应该是\[**由NFA状态构成的集合**]![[Pasted image 20251111201959.png]]
具体画法：先判断start state={A, B, F}，然后想start state遇到1会到哪里？...直到为每个状态都考虑一遍，则画完（注意：在画DFA的状态转移时，需要注意是“NFA状态集合”之间的转移，而非单个NFA状态间的转移）
### 将DFA转为代码
![[Pasted image 20251111212857.png]]有了状态转移表，就可以构造代码
### 构造出的DFA的特点
#### longest-match
![[Pasted image 20251111214736.png]]走得越深越好，走不下去才回退到起点+生成一个lexeme
#### priority rule
![[Pasted image 20251111214508.png]]![[Pasted image 20251111214603.png]]同一个DFA结点里的两个状态——只留一个（更高优先级的那个）
## lex的使用
![[Pasted image 20251111214932.png]]![[Pasted image 20251111215002.png]]输入RE，输出lexical analysis代码![[Pasted image 20251111215404.png]]
- C Declarations是一些\[需要放在生成的C程序里的代码]
- yylval是一个union类，表示“lexical analysis分析出来的值（对于整数是int，对于字符串是string，对于实数是double...）”
- Lex Definitions——为了方便，预定义一些符号
- "\%%"开始才是真正的Regular Expression的部分
![[Pasted image 20251111215412.png]]
- ADJ：把识别出的token“吃掉”，然后往前走
- yytext：工具给出的一个变量，表示“识别出来的字符串”
- "{digits}"：加"{}"表示识别的是之前定义的digits符号，而字符串"digits"本身 
- 倒数第二个RE：指注释和whitespace，吃掉（ADJ）即可
- 最后一个RE"."：表示剩下的那些模式——吃掉(ADJ)，然后报错
![[Pasted image 20251111215422.png]]
- 为了在lexical analysis中实现更复杂的逻辑（例如处理无限层嵌套的注释），可以自定义一些状态（也就是DFA有多个start state）
- 最后一行表示：刚进来的时候，就把状态设置成INITIAL，且这时候已经挪了一个字符，所以需要挪回来？~yyless(1)
# Parser
接过由Lexical Analysis得出的token sequence，构建parse tree
![[Pasted image 20251111221050.png]]![[Pasted image 20251111221056.png]]
## Context-Free Grammar(CFG)
术语：
- terminal(小写)——不可再通过production替换，一般是来自Lexical Analysis的token
- nonterminal(大写)——可以通过production替换为nonterminal/terminal
- start symbol S——Parser的输入
- production——替换规则
![[Pasted image 20251111221733.png]]production示例：
![[Pasted image 20251111221817.png]]
**Parser的整体思路**：对于一个S，反复运用production，将其一点一点替换为terminal的序列![[Pasted image 20251111221953.png]]
## Derivation
Parser进行上述操作不是为了获取nonterminal的序列，而是为了在一步一步替代(Derivation)过程中建立起Parse Tree
例如：![[Pasted image 20251111222419.png]]![[Pasted image 20251111222427.png]]
**Parse Tree的特点**：
- 叶子都为terminal
- 内部结点都为non-terminal
- 对叶子进行中序遍历，即可得到原来的输入（即来自Lexical Analysis的lexeme序列）

**Leftmost与Rightmost**：
![[Pasted image 20251111222642.png]]Leftmost Derivation——每次替换最左边的non-terminal
![[Pasted image 20251111222734.png]]
Rightmost Derivation——每次替换最右边的
## Ambiguity
![[Pasted image 20251111222939.png]]
![[Pasted image 20251111222929.png]]有时有多种production都可使用，建出来的树也有区别
### 解决二义性(Ambiguity)的方式
#### 重写grammar
原来：![[Pasted image 20251111223242.png]]
重写之后：![[Pasted image 20251111223256.png]]
保证了'\*'比'+'更优先，且保证这两个符号均为左结合
（理解：E变成了“只能用来拆成加法的玩意”，而T不仅可以是加法，还可以是乘法，因此，会先根据加法进行derivation，从而保证优先级）

**左结合与右结合**：
**左结合**和**右结合**是编程语言中运算符的结合性规则，决定了相同优先级运算符的计算顺序。
**左结合**表示从左向右计算，例如`a + b + c`先计算`a + b`，再与`c`相加。大多数运算符都是左结合的，如加减乘除、赋值运算符等。
**右结合**表示从右向左计算，例如`a = b = c`先计算`b = c`，再将结果赋给`a`。典型的右结合运算符包括赋值运算符、指数运算符（如Python中的`**`）等。
简单记忆：左结合从左到右，右结合从右到左，这决定了表达式中相同优先级运算符的运算顺序。
#### 直接标注
实际上，与其把grammar写得很复杂，其实也可以直接做一些declaration，把derivation的行为解释清楚？
## Top-down Parsing
### Recursive Descent Parsing